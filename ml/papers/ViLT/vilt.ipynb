{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViLT\n",
    "\n",
    "[李沐讲论文](https://www.youtube.com/watch?v=ug8YvZOjOCE&list=PLFXJ6jwg0qW-7UM8iUTj3qKqdhbQULP5I&index=28)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](01.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 之前的VLP方法有两个缺陷，一个是速度。因为要训练一个CNN网络。另外一个就是表达能力有限。在训练vision网络的时候，一般只用标注好类型的数据去训练。有多少类，最终输出也就有多少类"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](02.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 作者将VLT任务分了四类。分别是在三个任务的复杂程度，一个是vision网络，一个是lang网络，另外一个就是融合网络。作者这篇文章是第四种类型"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](03.png)\n",
    "![](04.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ViLT的架构很简单。讲语言和图像分别embedding，然后用transformer去训练。其中图像用了和ViT类似的patch作token的方法。两个序列前面都加了一个分类token（CLS）。同时位置和任务编号也加入了token，用以区分token位置和类型（图片还是文字）。\n",
    "\n",
    "2. loss function有三个，分别是\n",
    "   * 图像和文字是否match。输入为match的和打乱的\n",
    "   * masked lang model。让lang网络去预测下一个词\n",
    "   * word patch alignment：计算图片token和lang token的相似度\n",
    "\n",
    "3. 在处理文字和图像的时候，用了几个技巧。mask whole word 和 image augment"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
