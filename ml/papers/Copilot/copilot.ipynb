{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copilot\n",
    "\n",
    "![](01.png)\n",
    "\n",
    "[李沐讲论文](https://www.youtube.com/watch?v=oZriUGkQSNM)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](02.png)\n",
    "![](03.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 通过UT测试来评估模型的好坏\n",
    "   \n",
    "2. BLUE score 在评价code中是有问题的。文中用了`pass@k`的方法。每次产生n个候选，从其中随机抽取k个。其中只要有一个能够通过unit test即可。所以这个概率计算的是所有k个都没有通过unit test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](04.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. nucleus sample: 一般的生成模型在生成下一个词的时候，只会选取下一个最大可能的词。这样无论运行多少次，得到的都是一样的结果。这里的做法是选取top 95%的词，然后按照每个词的概率去抽样。每次就会生成不一样的结果。然后最后对所有结果进行筛选"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](05.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. temperature 的作用是减少不同数之间的差距，防止某个的prob太大，增加diversity。这跟exp的性质有关，指数增长，把差别指数放大了。而当数据差别比较大的时候，大的数就占主要权重了。所以上图中随着k的增加，最优的温度也要增加，以让更多的候选的概率差距不会过大\n",
    "\n",
    "![](06.png)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](07.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. DeepMind 的这篇文章跟前面的很类似，区别在于他将写代码完全看成了机器翻译问题。输入是问题描述，输出代码。所以用了transformer的encoder和decoder的架构（而前面GPT只用了decoder）。具体技术细节没有太多"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
