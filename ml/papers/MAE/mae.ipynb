{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAE\n",
    "\n",
    "[李沐讲论文](https://www.youtube.com/watch?v=mYlX2dpdHHM&list=PLFXJ6jwg0qW-7UM8iUTj3qKqdhbQULP5I&index=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](01.png)\n",
    "\n",
    "1. MAE 的架构相对比较清晰，就是将原始图片随机遮挡一部分，然后将剩下的部分跟ViT类似的方法去encode，而后再将输出重新sort回原始图片的顺序，同时加上mask的batch，用decoder去填充需要的遮挡部分。\n",
    "\n",
    "2. 在输入的时候，并没有完全模仿BERT，把mask的部分也作为输入，而是直接drop掉了。这样大大减少了输入的数据量，使得模型可以处理更大的数据\n",
    "\n",
    "3. 详细的细节如下\n",
    "\n",
    "![](02.png)\n",
    "![](03.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
