{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DETR\n",
    "\n",
    "[李沐讲论文](https://github.com/mli/paper-reading)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](01.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 这篇文章主要贡献是抛弃了之前目标检测各种预处理任务，直接端到端用transformer来做，通过集合预测的二分图匹配算loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](02.png)\n",
    "![](03.png)\n",
    "![](04.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. CNN + 位置编码作为transformer的输入，CNN虽然获取了图像位置信息，但是其展平成了一维的数组，其空间关系基本消失了。所以需要加入位置编码，说白了就是让原来在空间上相邻的，位置编码就越靠近\n",
    "\n",
    "2. 后面就是transformer的decoder，object queries就是一些初始化随机的位置编码，是可以学习的参数"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](05.png)\n",
    "![](06.png)\n",
    "![](07.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Loss Function 包括两部分，一部分是分类loss，一部分是bounding box loss。总的loss通过二分图匹配计算一个总的最小值"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](08.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
