{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [chibicc](https://github.com/rui314/chibicc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## va_list, va_start, va_arg\n",
    "\n",
    "```c\n",
    "// Takes a printf-style format string and returns a formatted string.\n",
    "char *format(char *fmt, ...) {\n",
    "  char *buf;\n",
    "  size_t buflen;\n",
    "  FILE *out = open_memstream(&buf, &buflen);\n",
    "\n",
    "  va_list ap;\n",
    "  va_start(ap, fmt);\n",
    "  vfprintf(out, fmt, ap);\n",
    "  va_end(ap);\n",
    "  fclose(out);\n",
    "  return buf;\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. va_* 这几个宏原理就是移动指针，如下\n",
    "\n",
    "```c\n",
    "typedef unsigned char *va_list;\n",
    "#define va_start(list, param) (list = (((va_list)&param) + sizeof(param)))\n",
    "#define va_arg(list, type)    (*(type *)((list += sizeof(type)) - sizeof(type)))\n",
    "\n",
    "```\n",
    "\n",
    "只不过在GCC里不是明确用宏定义的，而是内建函数\n",
    "\n",
    "\n",
    "![](resources/01.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "-----------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenize.c\n",
    "\n",
    "```c\n",
    "// Tokenize a given string and returns new tokens.\n",
    "Token *tokenize(File *file) {\n",
    "  current_file = file;\n",
    "\n",
    "  char *p = file->contents;\n",
    "  Token head = {};\n",
    "  Token *cur = &head;\n",
    "\n",
    "  at_bol = true;\n",
    "  has_space = false;\n",
    "\n",
    "  while (*p) {\n",
    "    // Skip line comments.\n",
    "    if (startswith(p, \"//\")) {\n",
    "      p += 2;\n",
    "      while (*p != '\\n')\n",
    "        p++;\n",
    "      has_space = true;\n",
    "      continue;\n",
    "    }\n",
    "\n",
    "    // Skip block comments.\n",
    "    if (startswith(p, \"/*\")) {\n",
    "      char *q = strstr(p + 2, \"*/\");\n",
    "      if (!q)\n",
    "        error_at(p, \"unclosed block comment\");\n",
    "      p = q + 2;\n",
    "      has_space = true;\n",
    "      continue;\n",
    "    }\n",
    "\n",
    "    // Skip newline.\n",
    "    if (*p == '\\n') {\n",
    "      p++;\n",
    "      at_bol = true;\n",
    "      has_space = false;\n",
    "      continue;\n",
    "    }\n",
    "\n",
    "    // Skip whitespace characters.\n",
    "    if (isspace(*p)) {\n",
    "      p++;\n",
    "      has_space = true;\n",
    "      continue;\n",
    "    }\n",
    "\n",
    "    // Numeric literal\n",
    "    if (isdigit(*p) || (*p == '.' && isdigit(p[1]))) {\n",
    "      char *q = p++;\n",
    "      for (;;) {\n",
    "        if (p[0] && p[1] && strchr(\"eEpP\", p[0]) && strchr(\"+-\", p[1]))\n",
    "          p += 2;\n",
    "        else if (isalnum(*p) || *p == '.')\n",
    "          p++;\n",
    "        else\n",
    "          break;\n",
    "      }\n",
    "      cur = cur->next = new_token(TK_PP_NUM, q, p);\n",
    "      continue;\n",
    "    }\n",
    "\n",
    "```\n",
    "\n",
    "把文件token化，比较简单，主要就几种情况\n",
    "\n",
    "1.注释 2.换行 3.空白 4.数字常量 5.字符串常量 6.关键字 7.运算符\n",
    "\n",
    "----------------------------------------------------------------------------\n",
    "-------------------------------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess.c"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Macro Algo: Dave Prosser Algo](resources/cpp.algo.pdf)\n",
    "\n",
    "[GCC Macros](https://gcc.gnu.org/onlinedocs/cpp/Macros.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](resources/02.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dave 算法：\n",
    "\n",
    "1. 每个token都有一个hideset，表示这个token之前是由哪个macro（string）替换来的。初始的时候都是空的（{}）\n",
    "\n",
    "2. 在macro expand的过程中，如果当前这个token的string在hideset中，说明之前已经发生过一次替换，那么这次就不再替换（这就防止了循环替换）。\n",
    "   \n",
    "   \n",
    "3. 如果hideset中没有出现过，就把当前token替换成对应的macro，同时将原来token的string放入到hideset中（也就是代码中的 $HS \\cup \\{T\\}$）\n",
    "\n",
    "4. 如果是function-like 的macro（注：macro定义时的参数较parameter，传入的参数叫actual或argument），先对传入的参数（actuals）作macro expand，然后在用expanded之后的actual去替换macro中的parameter，同时actual的hideset `HS'`和parameter的hideset `HS`取交集，也就是代码中的$(HS \\cap HS')$\n",
    "\n",
    "5. 在代码中的macro expand，针对每一个token，会循环去作expand，直到当前的token无法再expand了，再去处理下一个token。这样就解决了macro嵌套定义的问题，例如\n",
    "\n",
    "    ```c\n",
    "    #define A 1\n",
    "    #define B A\n",
    "    #define C B\n",
    "    #define D C+B\n",
    "    ```\n",
    "----------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### static Token *preprocess2(Token *tok)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```c\n",
    "// Visit all tokens in `tok` while evaluating preprocessing\n",
    "// macros and directives.\n",
    "static Token *preprocess2(Token *tok) {\n",
    "  Token head = {};\n",
    "  Token *cur = &head;\n",
    "\n",
    "  while (tok->kind != TK_EOF) {\n",
    "    // If it is a macro, expand it.\n",
    "    if (expand_macro(&tok, tok))\n",
    "      continue;\n",
    "\n",
    "    // Pass through if it is not a \"#\".\n",
    "    if (!is_hash(tok)) {\n",
    "      tok->line_delta = tok->file->line_delta;\n",
    "      tok->filename = tok->file->display_name;\n",
    "      cur = cur->next = tok;\n",
    "      tok = tok->next;\n",
    "      continue;\n",
    "    }\n",
    "\n",
    "    Token *start = tok;\n",
    "    tok = tok->next;\n",
    "\n",
    "```\n",
    "1. `expand_macro` 展开当前token，如果可以展开，返回true，那么就continue，继续展开当前token，直到无法展开，再往下继续处理\n",
    "\n",
    "-----------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### static bool expand_macro(Token **rest, Token *tok)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c\n",
    "// If tok is a macro, expand it and return true.\n",
    "// Otherwise, do nothing and return false.\n",
    "static bool expand_macro(Token **rest, Token *tok) {\n",
    "  if (hideset_contains(tok->hideset, tok->loc, tok->len))\n",
    "    return false;\n",
    "\n",
    "  /** xitongsys\n",
    "   * \n",
    "   * find_macro 从全局的hashmap中查找当前token是否是一个macro\n",
    "   * \n",
    "  **/\n",
    "  Macro *m = find_macro(tok);\n",
    "  if (!m)\n",
    "    return false;\n",
    "\n",
    "  // Built-in dynamic macro application such as __LINE__\n",
    "  if (m->handler) {\n",
    "    *rest = m->handler(tok);\n",
    "    (*rest)->next = tok->next;\n",
    "    return true;\n",
    "  }\n",
    "\n",
    "\n",
    "  /** xitongsys\n",
    "   * \n",
    "   * 对于Object-like的macro，将当前token的name string和之前的hideset union作为新的hideset\n",
    "   * 因为macro expand之后可能会有多个token，所以这里body是一个链表\n",
    "   * \n",
    "  **/\n",
    "  // Object-like macro application\n",
    "  if (m->is_objlike) {\n",
    "    Hideset *hs = hideset_union(tok->hideset, new_hideset(m->name));\n",
    "    Token *body = add_hideset(m->body, hs);\n",
    "    for (Token *t = body; t->kind != TK_EOF; t = t->next)\n",
    "      t->origin = tok;\n",
    "    *rest = append(body, tok->next);\n",
    "    (*rest)->at_bol = tok->at_bol;\n",
    "    (*rest)->has_space = tok->has_space;\n",
    "    return true;\n",
    "  }\n",
    "\n",
    "  // If a funclike macro token is not followed by an argument list,\n",
    "  // treat it as a normal identifier.\n",
    "  if (!equal(tok->next, \"(\"))\n",
    "    return false;\n",
    "\n",
    "  // Function-like macro application\n",
    "  Token *macro_token = tok;\n",
    "  MacroArg *args = read_macro_args(&tok, tok, m->params, m->va_args_name);\n",
    "  Token *rparen = tok;\n",
    "\n",
    "  // Tokens that consist a func-like macro invocation may have different\n",
    "  // hidesets, and if that's the case, it's not clear what the hideset\n",
    "  // for the new tokens should be. We take the interesection of the\n",
    "  // macro token and the closing parenthesis and use it as a new hideset\n",
    "  // as explained in the Dave Prossor's algorithm.\n",
    "  Hideset *hs = hideset_intersection(macro_token->hideset, rparen->hideset);\n",
    "  hs = hideset_union(hs, new_hideset(m->name));\n",
    "\n",
    "  Token *body = subst(m->body, args);\n",
    "  body = add_hideset(body, hs);\n",
    "  for (Token *t = body; t->kind != TK_EOF; t = t->next)\n",
    "    t->origin = macro_token;\n",
    "  *rest = append(body, tok->next);\n",
    "  (*rest)->at_bol = macro_token->at_bol;\n",
    "  (*rest)->has_space = macro_token->has_space;\n",
    "  return true;\n",
    "}\n",
    "```\n",
    "1. see comments in the code by xitongsys\n",
    "\n",
    "---------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c\n",
    "static Token *add_hideset(Token *tok, Hideset *hs) {\n",
    "  Token head = {};\n",
    "  Token *cur = &head;\n",
    "\n",
    "  for (; tok; tok = tok->next) {\n",
    "    Token *t = copy_token(tok);\n",
    "    t->hideset = hideset_union(t->hideset, hs);\n",
    "    cur = cur->next = t;\n",
    "  }\n",
    "  return head.next;\n",
    "}\n",
    "```\n",
    "\n",
    "之所以把hs加到整个token list里面是因为macro展开的时候，可以有多个token，因此macro expand的结果是一个token list。具体看Macro struct的内容。其中body就是这个macro要展开的token list\n",
    "\n",
    "```c\n",
    "typedef struct Macro Macro;\n",
    "struct Macro {\n",
    "  char *name;\n",
    "  bool is_objlike; // Object-like or function-like\n",
    "  MacroParam *params;\n",
    "  char *va_args_name;\n",
    "  Token *body;\n",
    "  macro_handler_fn *handler;\n",
    "};\n",
    "```\n",
    "\n",
    "----------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c\n",
    "// Append tok2 to the end of tok1.\n",
    "static Token *append(Token *tok1, Token *tok2) {\n",
    "  if (tok1->kind == TK_EOF)\n",
    "    return tok2;\n",
    "\n",
    "  Token head = {};\n",
    "  Token *cur = &head;\n",
    "\n",
    "  for (; tok1->kind != TK_EOF; tok1 = tok1->next)\n",
    "    cur = cur->next = copy_token(tok1);\n",
    "  cur->next = tok2;\n",
    "  return head.next;\n",
    "}\n",
    "```\n",
    "\n",
    "1. 代码中用很多对两个token list的操作，往往都是第一个参数不变，而是重新拷贝一份，第二个参数追加上去，返回 （新拷贝的1 + 老的2）\n",
    "\n",
    "2. `cur = cur->next = copy_token(tok1);` 赋值小技巧"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------\n",
    "------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parse.c\n",
    "\n",
    "```c\n",
    "// This file contains a recursive descent parser for C.\n",
    "//\n",
    "// Most functions in this file are named after the symbols they are\n",
    "// supposed to read from an input token list. For example, stmt() is\n",
    "// responsible for reading a statement from a token list. The function\n",
    "// then construct an AST node representing a statement.\n",
    "//\n",
    "// Each function conceptually returns two values, an AST node and\n",
    "// remaining part of the input tokens. Since C doesn't support\n",
    "// multiple return values, the remaining tokens are returned to the\n",
    "// caller via a pointer argument.\n",
    "//\n",
    "// Input tokens are represented by a linked list. Unlike many recursive\n",
    "// descent parsers, we don't have the notion of the \"input token stream\".\n",
    "// Most parsing functions don't change the global state of the parser.\n",
    "// So it is very easy to lookahead arbitrary number of tokens in this\n",
    "// parser.\n",
    "```\n",
    "\n",
    "整体逻辑比较简单。就是递归下降去parse所有的token构建AST（难点在于把所有语句的文法写清楚）。当然内部有些技巧\n",
    "\n",
    "---------------------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 复习下编译原理的一些概念\n",
    "\n",
    "![](resources/04.png)\n",
    "![](resources/05.png)\n",
    "![](resources/06.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. LL 剖析，就是从左向右输入，从左向有进行替换。上例中，当看到第一个是`(`后，就进行2替换。第二个括号，继续进行2替换。后面都是3替换\n",
    "\n",
    "2. 从替换过程可以看到，是自顶向下的构建"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](resources/07.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 左递归\n",
    "\n",
    "![](resources/08.png)\n",
    "![](resources/09.png)\n",
    "![](resources/10.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Paull's Algorithm](resources/removing_left_recursion_from_context_free_grammars.pdf)\n",
    "\n",
    "![](resources/11.png)\n",
    "![](resources/12.png)\n",
    "![](resources/13.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 对于直接左递归，$A \\rightarrow A\\alpha_1|\\beta_1$，所有左递归的production,最终的展开必然是非左递归的某一个，也就是其中的$\\beta_1$。而左递归production中的$\\alpha_1$，则可以重复多次。因此将$A \\rightarrow \\beta_1A'，A' \\rightarrow \\alpha_1A'$，得到了和之前一样的语义\n",
    "\n",
    "2. 对于间接左递归，将所有nonterminals排序，只允许从前往后的展开，不允许从后往前。例如$i>j, A_i \\rightarrow A_j\\alpha$就需要移除。而$A_j$在前面已经处理过了，它所有展开一定只包括$A_k, k<j$。因此消除的时候，只要把$A_j$替换成所有其可能的展开即可\n",
    "\n",
    "3. 替换左递归后往往会导致结合律发生变化，前面wiki中也提到了几种方法。如果手写praser，最简单的就是在构造语法树的时候做特殊处理，重新安排顺序，例如龙书中的这个例子\n",
    "\n",
    "![](resources/14.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 代码笔记\n",
    "\n",
    "\n",
    "```c\n",
    "// program = (typedef | function-definition | global-variable)*\n",
    "Obj *parse(Token *tok) {\n",
    "  declare_builtin_functions();\n",
    "  globals = NULL;\n",
    "\n",
    "  while (tok->kind != TK_EOF) {\n",
    "    VarAttr attr = {};\n",
    "    Type *basety = declspec(&tok, tok, &attr);\n",
    "\n",
    "    // Typedef\n",
    "    if (attr.is_typedef) {\n",
    "      tok = parse_typedef(tok, basety);\n",
    "      continue;\n",
    "    }\n",
    "\n",
    "    // Function\n",
    "    if (is_function(tok)) {\n",
    "      tok = function(tok, basety, &attr);\n",
    "      continue;\n",
    "    }\n",
    "\n",
    "    // Global variable\n",
    "    tok = global_variable(tok, basety, &attr);\n",
    "  }\n",
    "\n",
    "  for (Obj *var = globals; var; var = var->next)\n",
    "    if (var->is_root)\n",
    "      mark_live(var);\n",
    "\n",
    "  // Remove redundant tentative definitions.\n",
    "  scan_globals();\n",
    "  return globals;\n",
    "}\n",
    "```\n",
    "\n",
    "1. 最顶层的parse，因为像#include，#define等preprocess的语句，已经在preprocess过程中转换成普通token了。所以在这里只有这三种情况：`typedef, function-definition, global-variable`\n",
    "\n",
    "-------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "---------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some functions\n",
    "\n",
    "```c\n",
    "/* Open a stream that writes into a malloc'd buffer that is expanded as\n",
    "   necessary.  *BUFLOC and *SIZELOC are updated with the buffer's location\n",
    "   and the number of characters written on fflush or fclose.  */\n",
    "extern FILE *open_memstream (char **__bufloc, size_t *__sizeloc) __THROW\n",
    "  __attribute_malloc__ __attr_dealloc_fclose __wur;\n",
    "```\n",
    "\n",
    "------------------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](resources/03.png)\n",
    "\n",
    "---------------------------"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
