{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 熵 entropy\n",
    "\n",
    "\n",
    "### 熵\n",
    "$H(x) = - \\Sigma_x P(x)log P(x)$\n",
    "\n",
    "### 条件熵\n",
    "$H(y|x) = - \\Sigma_x P(x) \\Sigma_y P(y|x) log P(y|x) $\n",
    "\n",
    "### 联合熵\n",
    "\n",
    "$H(x,y) = - \\Sigma_x \\Sigma_y P(x,y) log P(x,y)$\n",
    "\n",
    "\n",
    "### 几个关系\n",
    "\n",
    "1. $ H(x,y) = H(x|y) + H(y) $\n",
    "\n",
    "证明：\n",
    "$$\\begin{aligned}\n",
    "H(x,y) &= - \\Sigma_x \\Sigma_y P(x,y) log P(x,y) \\\\\n",
    "       &= - \\Sigma_x \\Sigma_y P(x|y)P(y) log P(x|y)P(y) \\\\\n",
    "       &= - [ \\Sigma_x \\Sigma_y P(x|y)P(y) log P(x|y) + \\Sigma_x \\Sigma_y P(x|y)P(y) log P(y) ] \\\\\n",
    "       &= - [ \\Sigma_y P(y) \\Sigma_x P(x|y) log P(x|y) + \\Sigma_y P(y)log P(y) \\Sigma_x P(x|y)] \\\\\n",
    "       &= H(x|y) + H(y)\n",
    "\\end{aligned}$$\n",
    "\n",
    "\n",
    "2. $ H(x) + H(y) >= H(x,y) $\n",
    "\n",
    "证明：\n",
    "$$\\begin{aligned}\n",
    "H(x) &= - \\Sigma_x P(x) log P(x) \\\\\n",
    "     &= - \\Sigma_x \\Sigma_y P(x,y) log P(x)\n",
    "\\end{aligned}$$\n",
    "    \n",
    "$$\\begin{aligned}\n",
    "H(y) &= - \\Sigma_y P(y) log P(y) \\\\\n",
    "     &= - \\Sigma_y \\Sigma_x P(x,y) log P(y)\n",
    "\\end{aligned}$$\n",
    "\n",
    "所以有\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\n",
    "H(x) + H(y) = -\\Sigma_x \\Sigma_y P(x,y) log P(x)P(y) \n",
    "\n",
    "\\end{aligned}$$\n",
    "\n",
    "定义$I(x,y)$如下，其实就是互信息\n",
    "\n",
    "$$\\begin{aligned}\n",
    "I(x,y) &= H(x) + H(y) - H(x,y) \\\\\n",
    "       &= - \\Sigma_x \\Sigma_y P(x,y) log \\frac{P(x)P(y)}{P(x,y)} \\\\\n",
    "       & = \\Sigma_x \\Sigma_y P(x,y) log \\frac{P(x,y)}{P(x)P(y)}\n",
    "\\end{aligned}$$\n",
    "\n",
    "此处需要用到一个对数求和不等式，若 $a = \\Sigma a_i, b = \\Sigma b_i$，则有\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\n",
    "\\Sigma a_i log\\frac{a_i}{b_i} >= a log\\frac{a}{b}\n",
    "\n",
    "\\end{aligned}$$\n",
    "\n",
    "当且仅当$\\frac{a_i}{b_i} = \\frac{a}{b}$时取等号。\n",
    "\n",
    "\n",
    "直接利用这个不等式，有$I(x,y) >= 1 \\times log \\frac{1}{1} = 0$，得证。\n",
    "\n",
    "\n",
    "3. $H(y|x) <= H(y)$\n",
    "\n",
    "证明：\n",
    "$$\n",
    "H(y|x) = H(x,y) - H(x) <= H(x) + H(y) - H(x) = H(y)\n",
    "$$\n",
    "\n",
    "这个关系的含义是增加条件，不会使得原来的熵增加。比如有一个数组 [0,1,1,0,0,0]，其本身有一个熵，这个就是\n",
    "\n",
    "$$ \n",
    "\n",
    "H_0 = -(\\frac{1}{3}log(\\frac{1}{3}) + \\frac{2}{3}log\\frac{2}{3})\n",
    "\n",
    "$$\n",
    "\n",
    "如果将其任意拆分成两个数组，比如 [0,1,1],[0,0,0]，计算其条件熵\n",
    "\n",
    "$$\n",
    "\n",
    "H_c = -[\\frac{1}{2} \\times (\\frac{1}{3}log(\\frac{1}{3}) + \\frac{2}{3}log\\frac{2}{3}) + \\frac{1}{2} \\times 0]\n",
    "\n",
    "$$\n",
    "\n",
    "一定有 $H_c <= H_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交叉熵 Cross Entropy [REF](https://en.wikipedia.org/wiki/Cross_entropy)\n",
    "\n",
    "![](ce01.png)\n",
    "![](ce02.png)\n",
    "\n",
    "\n",
    "\n",
    "1. 最大化似然函数就等价于最小化交叉熵\n",
    "\n",
    "2. $\\sum_i^n p_i log(q_i)$ 这个函数的最大值就是当$q_i = p_i$的时候，考虑拉格朗日乘子法\n",
    "\n",
    "$g = \\sum_{i=0}^n p_i log(q_i) - \\lambda (\\sum_{i=0}^n q_i - 1)$\n",
    "\n",
    "所以有 $\\frac{\\partial g}{\\partial q_i} = \\frac{p_i}{q_i} - \\lambda = 0$\n",
    "\n",
    "即 $\\frac{p_i}{q_i} = \\lambda $。所有的都一样，所以$q_i = p_i$\n",
    "\n",
    "3. 最小化cross entropy的过程，就是让$q_i$ 不断趋近于 $p_i$。所以可以用cross entropy来作为分类问题的loss function"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
